{
  "name": "Python Performance Error Patterns",
  "description": "Performance optimization patterns for Python applications",
  "version": "1.0.0",
  "rules": [
    {
      "id": "python_performance_memory_leak",
      "pattern": "memory leak|memory usage keeps increasing|memory not released|circular reference|reference cycle",
      "type": "MemoryError",
      "description": "Memory leak detected in Python application",
      "root_cause": "memory_leak",
      "suggestion": "Check for circular references, clear caches, use weak references for callbacks, ensure file handles and connections are properly closed",
      "category": "python",
      "subcategory": "memory",
      "severity": "high",
      "confidence": "medium",
      "tags": ["performance", "memory", "leak"]
    },
    {
      "id": "python_performance_slow_loop",
      "pattern": "slow loop|inefficient iteration|performance degradation in loop|taking too long to iterate",
      "type": "PerformanceError",
      "description": "Inefficient loop or iteration pattern detected",
      "root_cause": "inefficient_algorithm",
      "suggestion": "Use list comprehensions, generator expressions, built-in functions (map, filter), or numpy for numerical operations instead of explicit loops",
      "category": "python",
      "subcategory": "algorithm",
      "severity": "medium",
      "confidence": "high",
      "tags": ["performance", "loop", "optimization"]
    },
    {
      "id": "python_performance_string_concatenation",
      "pattern": "string concatenation in loop|\\+= in loop with strings|inefficient string building",
      "type": "PerformanceError",
      "description": "Inefficient string concatenation in loop",
      "root_cause": "inefficient_string_operation",
      "suggestion": "Use str.join() or list append/join pattern instead of += for string concatenation in loops",
      "category": "python",
      "subcategory": "string",
      "severity": "medium",
      "confidence": "high",
      "tags": ["performance", "string", "memory"]
    },
    {
      "id": "python_performance_list_append",
      "pattern": "list\\.insert\\(0|prepending to list|inefficient list insertion",
      "type": "PerformanceError",
      "description": "Inefficient list prepend operation",
      "root_cause": "inefficient_data_structure",
      "suggestion": "Use collections.deque for frequent prepend operations or build list in reverse and reverse at end",
      "category": "python",
      "subcategory": "data_structure",
      "severity": "medium",
      "confidence": "high",
      "tags": ["performance", "list", "algorithm"]
    },
    {
      "id": "python_performance_global_lookup",
      "pattern": "frequent global variable access|global lookup in loop|LEGB lookup overhead",
      "type": "PerformanceError",
      "description": "Excessive global variable lookups in performance-critical code",
      "root_cause": "inefficient_variable_access",
      "suggestion": "Cache global variables as local variables in functions, especially in loops",
      "category": "python",
      "subcategory": "scope",
      "severity": "low",
      "confidence": "medium",
      "tags": ["performance", "scope", "optimization"]
    },
    {
      "id": "python_performance_repeated_computation",
      "pattern": "repeated calculation|redundant computation|calculating same value multiple times",
      "type": "PerformanceError",
      "description": "Same computation performed multiple times",
      "root_cause": "redundant_computation",
      "suggestion": "Cache computed values, use memoization with functools.lru_cache, or move invariant computations outside loops",
      "category": "python",
      "subcategory": "algorithm",
      "severity": "medium",
      "confidence": "medium",
      "tags": ["performance", "cache", "optimization"]
    },
    {
      "id": "python_performance_database_n_plus_1",
      "pattern": "N\\+1 query|multiple queries in loop|database query in loop|inefficient ORM usage",
      "type": "PerformanceError",
      "description": "N+1 query problem detected",
      "root_cause": "database_inefficiency",
      "suggestion": "Use select_related() or prefetch_related() in Django, joinedload() in SQLAlchemy, or fetch related data in single query",
      "category": "python",
      "subcategory": "database",
      "severity": "high",
      "confidence": "high",
      "tags": ["performance", "database", "orm"]
    },
    {
      "id": "python_performance_large_data_in_memory",
      "pattern": "loading entire file|reading all data into memory|MemoryError.*large.*file|out of memory.*read",
      "type": "MemoryError",
      "description": "Loading large dataset entirely into memory",
      "root_cause": "memory_inefficiency",
      "suggestion": "Use generators, iterators, or streaming approaches; process data in chunks; use memory-mapped files with mmap",
      "category": "python",
      "subcategory": "memory",
      "severity": "high",
      "confidence": "high",
      "tags": ["performance", "memory", "streaming"]
    },
    {
      "id": "python_performance_inefficient_regex",
      "pattern": "regex performance|catastrophic backtracking|slow regular expression|regex timeout",
      "type": "PerformanceError",
      "description": "Inefficient regular expression causing performance issues",
      "root_cause": "inefficient_regex",
      "suggestion": "Simplify regex, avoid nested quantifiers, use non-capturing groups (?:), consider using string methods for simple cases",
      "category": "python",
      "subcategory": "regex",
      "severity": "medium",
      "confidence": "medium",
      "tags": ["performance", "regex", "pattern"]
    },
    {
      "id": "python_performance_synchronous_io",
      "pattern": "blocking I/O|synchronous requests in loop|sequential API calls|slow I/O operations",
      "type": "PerformanceError",
      "description": "Synchronous I/O operations causing performance bottleneck",
      "root_cause": "blocking_io",
      "suggestion": "Use asyncio for concurrent I/O, threading for I/O-bound tasks, or multiprocessing for CPU-bound tasks",
      "category": "python",
      "subcategory": "concurrency",
      "severity": "high",
      "confidence": "medium",
      "tags": ["performance", "io", "concurrency"]
    },
    {
      "id": "python_performance_unnecessary_copies",
      "pattern": "unnecessary copy|redundant list copy|deepcopy performance|copying large objects",
      "type": "PerformanceError",
      "description": "Creating unnecessary copies of large data structures",
      "root_cause": "unnecessary_copying",
      "suggestion": "Use views, slices, or iterators instead of copies; pass by reference; use copy-on-write patterns",
      "category": "python",
      "subcategory": "memory",
      "severity": "medium",
      "confidence": "medium",
      "tags": ["performance", "memory", "copying"]
    },
    {
      "id": "python_performance_inefficient_serialization",
      "pattern": "slow (json|pickle) serialization|serialization performance|large object serialization",
      "type": "PerformanceError",
      "description": "Inefficient serialization of large objects",
      "root_cause": "serialization_inefficiency",
      "suggestion": "Use more efficient formats (msgpack, protobuf), serialize incrementally, or use specialized libraries like ujson",
      "category": "python",
      "subcategory": "serialization",
      "severity": "medium",
      "confidence": "medium",
      "tags": ["performance", "serialization", "io"]
    },
    {
      "id": "python_performance_gil_contention",
      "pattern": "GIL contention|threading performance|CPU-bound threads|poor multithread performance",
      "type": "PerformanceError",
      "description": "Global Interpreter Lock (GIL) contention in CPU-bound threading",
      "root_cause": "gil_contention",
      "suggestion": "Use multiprocessing for CPU-bound tasks, asyncio for I/O-bound tasks, or consider using Cython/NumPy for numerical computations",
      "category": "python",
      "subcategory": "concurrency",
      "severity": "high",
      "confidence": "high",
      "tags": ["performance", "gil", "threading"]
    },
    {
      "id": "python_performance_import_overhead",
      "pattern": "slow import|import time|heavy imports|circular imports causing slowdown",
      "type": "PerformanceError",
      "description": "Heavy import overhead slowing down application startup",
      "root_cause": "import_overhead",
      "suggestion": "Use lazy imports, import only what's needed, avoid circular imports, consider using __all__ to limit exports",
      "category": "python",
      "subcategory": "import",
      "severity": "medium",
      "confidence": "medium",
      "tags": ["performance", "import", "startup"]
    },
    {
      "id": "python_performance_inefficient_dataframe",
      "pattern": "iterrows|slow pandas operation|dataframe apply|inefficient pandas",
      "type": "PerformanceError",
      "description": "Inefficient pandas DataFrame operations",
      "root_cause": "dataframe_inefficiency",
      "suggestion": "Use vectorized operations, avoid iterrows(), use numpy operations where possible, consider using numba for complex operations",
      "category": "python",
      "subcategory": "pandas",
      "severity": "high",
      "confidence": "high",
      "tags": ["performance", "pandas", "dataframe"]
    }
  ]
}